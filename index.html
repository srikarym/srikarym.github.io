<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Srikar Yellapragada</title>

  <meta name="author" content="Srikar Yellapragada">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Srikar Yellapragada</name>
                  </p>
                  <img src="images/me.JPG" class="img_me">
                  <p>I am a PhD student in the Computer Science department at <a
                      href="https://www.stonybrook.edu/">Stony Brook University</a>, advised by <a
                      href="https://www3.cs.stonybrook.edu/~samaras/">Dimitris Samaras</a> My research is focused on
                    Computer vision.
                    Before this, I was a Software Engineer at <a href="https://www.bloomberg.com/company/">Bloomberg
                      LP</a>; our team built an ETL pipeline for the ingestion of third party data.
                  </p>
                  <p>
                    In 2020, I obtained my Masters in Computer Science from <a
                      href="https://cims.nyu.edu/dynamic/">NYU</a>, where I worked with <a
                      href="https://kyunghyuncho.me/">Kyunghyun Cho's</a> group on <a
                      href="https://cs.nyu.edu/media/publications/Yellapragada__Manikanta_Srikar_-_MS_Thesis.pdf">Similarity
                      of Neural Networks</a>, and interned at <a href="https://www.ibm.com/watson-health">IBM Watson
                      Health</a>.
                  </p>
                  <p>
                    Previously, I obtained a B.Tech in Electrical Engineering from <a href="https://iith.ac.in/">Indian
                      Institute of Technology, Hyderabad,</a> where I worked with <a
                      href="https://people.iith.ac.in/sumohana/">Sumohana Channappayya</a> on Image Processing. I
                    interned at <a href="https://val.cds.iisc.ac.in/">Video Analytics Lab, IISc Bangalore</a>.
                  </p>
                  <p>In my free time, I enjoy playing video games. I'm a big fan of strategy games, such as Dota 2 and
                    Age of Empires 2. </p>
                  <br>
                  <p style="text-align:center">
                    <a href="mailto:srikary@cs.stonybrook.edu">Email</a> &nbsp/&nbsp
                    <a href="https://drive.google.com/file/d/1bRniIjx6jSsSGMWd-BdiloO-gO9LbonH/view?usp=sharing">CV</a>
                    &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/srikarym/">Linkedin</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=DVMnHboAAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://twitter.com/ymsrikar">Twitter</a> &nbsp/&nbsp
                    <a href="https://github.com/srikarym/">Github</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- News -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding-left:20px;padding-right:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                </td>
              </tr>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <ul>
                    <li style="margin-bottom: 10px;"><span style="background-color: yellow;">[Feb. 2024]</span> Our
                      large image generation research has been accepted at CVPR 2024.</li>
                    <li style="margin-bottom: 10px;">[Oct 2023] PathLDM has been accepted for WACV, 2024. </li>
                    <li style="margin-bottom: 10px;">[Aug 2023] Our study on conditional generation with denoiser
                      representations has been accepted
                      at BMVC 2023.</li>
                    <li>[Aug 2022] Started my PhD at Stony Brook University. </li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>



          <!-- Publications -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications / Pre-prints</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- Learned representation-guided diffusion models for large-image generation -->
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <a href='images/large_img.png'><img src='images/large_img.png' class="img_pub"></a>
                  <a href="https://arxiv.org/abs/2312.07330">
                    <papertitle>Learned representation-guided diffusion models for large-image generation</papertitle>
                  </a>
                  <br>
                  Alexandros Graikos*, <strong>Srikar Yellapragada*</strong>, Minh-Quan Le, Saarthak Kapse, Prateek
                  Prasanna, Joel Saltz, Dimitris Samaras
                  <br>
                  <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/pdf/2312.07330.pdf">paper</a>
                  <p> We condition latent diffusion models with SSL embeddings, and generate large images in
                    histopathology and satellite imagery. </p>

                </td>
              </tr>

              <!-- PathLDM: Text conditioned Latent Diffusion Model for Histopathology -->
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <a href='images/pathldm.png'><img src='images/pathldm.png' class="img_pub"></a>
                  <a href="https://arxiv.org/abs/2309.00748">
                    <papertitle>PathLDM: Text conditioned Latent Diffusion Model for Histopathology</papertitle>
                  </a>
                  <br>
                  <strong>Srikar Yellapragada*</strong>, Alexandros Graikos*, Prateek Prasanna, Tahsin Kurc, Joel Saltz,
                  Dimitris Samaras
                  <br>
                  <em>In Winter Conference on Applications of Computer Vision (WACV)</em>, 2024
                  <br>
                  <a href="https://arxiv.org/pdf/2309.00748.pdf">paper</a> /
                  <a href="https://github.com/cvlab-stonybrook/PathLDM">code</a>
                  <p style=" display: flex"> We build a text conditioned LDM for histopathology using GPT summarized
                    text reports and CLIP embeddings. </p>
                </td>
              </tr>

              <!-- Conditional Generation from Unconditional Diffusion Models using Denoiser Representations -->
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <a href='images/diff_cond.png'><img src='images/diff_cond.png' class="img_pub"></a>
                  <a href="https://arxiv.org/abs/2306.01900">
                    <papertitle>Conditional Generation from Unconditional Diffusion Models using Denoiser
                      Representations</papertitle>
                  </a>
                  <br>
                  Alexandros Graikos, <strong>Srikar Yellapragada</strong>, Dimitris Samaras
                  <br>
                  <em>In British Machine Vision Conference (BMVC)</em>, 2023
                  <br>
                  <a href="https://papers.bmvc2023.org/0478.pdf">paper</a> /
                  <a href="https://github.com/cvlab-stonybrook/fewshot-conditional-diffusion">code</a> /
                  <a href="https://bmvc2022.mpi-inf.mpg.de/BMVC2023/0478_poster.pdf">poster</a>



                  <p style=" display: flex"> We condition unconditional models in limited data scenarios using an
                    auxiliary network built upon denoiser representations. </p>
                </td>
              </tr>


              <!-- Are the proposed similarity metrics also a measure of functional similarity? -->
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <a href='images/thesis.png'><img src='images/thesis.png' class="img_pub"></a>
                  <a href="https://cs.nyu.edu/media/publications/Yellapragada__Manikanta_Srikar_-_MS_Thesis.pdf">
                    <papertitle>Are the proposed similarity metrics also a measure of functional similarity?
                    </papertitle>
                  </a>
                  <br>
                  <strong>Manikanta Srikar Yellapragada</strong>
                  <br>
                  <em>Masters Thesis</em>, 2020
                  <br>
                  <a
                    href="https://cs.nyu.edu/media/publications/Yellapragada__Manikanta_Srikar_-_MS_Thesis.pdf">paper</a>

                  <p style=" display: flex"> Short ans: NO. <br> Existing representation similarity metrics cannot fully
                    capture the output (functional) similiarity of a neural network. </p>
                </td>
              </tr>


              <!-- Deep learning based detection of acute aortic syndrome in contrast CT images -->
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <a href='images/isbi.png'><img src='images/isbi.png' class="img_pub"></a>
                  <a href="https://arxiv.org/abs/2004.01648">
                    <papertitle>Deep learning based detection of acute aortic syndrome in contrast CT images
                    </papertitle>
                  </a>
                  <br>
                  <strong>Manikanta Srikar Yellapragada</strong>, Yiting Xie, Benedikt Graf, David Richmond, Arun
                  Krishnan, Arkadiusz Sitek
                  <br>
                  <em>In International Symposium on Biomedical Imaging (ISBI)</em>, 2020
                  <br>
                  <a href="https://arxiv.org/pdf/2004.01648.pdf">paper</a>
                </td>
              </tr>


              <!-- Automatic diagnosis of pulmonary embolism using an attention-guided framework: a large-scale study -->
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <a href='images/midl.png'><img src='images/midl.png' height="80px" class="img_pub"></a>
                  <a href="http://proceedings.mlr.press/v121/shi20a/shi20a.pdf">
                    <papertitle>Automatic diagnosis of pulmonary embolism using an attention-guided framework: a
                      large-scale study</papertitle>
                  </a>
                  <br>
                  Luyao Shi, Deepta Rajan, Shafiq Abedin, <strong>Manikanta Srikar Yellapragada</strong>, David Beymer,
                  Ehsan Dehghan
                  <br>
                  <em>In Medical Imaging with Deep Learning (MIDL)</em>, 2020
                  <br>
                  <a href="http://proceedings.mlr.press/v121/shi20a/shi20a.pdf">paper</a>
                </td>
              </tr>

              <!-- Optical character recognition (OCR) for Telugu: Database, algorithm and application -->
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">
                  <a href='images/icip.png'><img src='images/icip.png' class="img_pub"></a>
                  <a href="https://arxiv.org/abs/1711.07245">
                    <papertitle>Optical character recognition (OCR) for Telugu: Database, algorithm and application
                    </papertitle>
                  </a>
                  <br>
                  Konkimalla Chandra Prakash, <strong>Y.M.Srikar</strong>, Gayam Trishal, Souraj Mandal, Sumohana S
                  Channappayya
                  <br>
                  <em>In International Conference on Image Processing (ICIP)</em>, 2018
                  <br>
                  <a href="https://arxiv.org/pdf/1711.07245.pdf">paper</a> /
                  <a href="https://github.com/srikarym/OCR_Telugu_code">code</a>
                </td>
              </tr>

            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">

                    <a href="https://jonbarron.info/">Credits</a>

                    <br>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

</body>

</html>